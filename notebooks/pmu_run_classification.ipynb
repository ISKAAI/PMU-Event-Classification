{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7dc489",
   "metadata": {},
   "source": [
    "This notebook implement a Recurrent Neural Network (RNN) for power system event calssification. \n",
    "\n",
    "The workflow includes data preprocessing, sequence construction, model training and evaluation.\n",
    "\n",
    "To reproduce the results, run all cell sequentially. The dataset file should be placed in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3d226",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Reproducibility\n",
    "Seed = 42\n",
    "np.random.seed(Seed)\n",
    "torch.manual_seed(Seed)\n",
    "# device setting\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f0e91",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Bus39_Competition_Data.xlsx'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca42dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('TIMESTAMP').reset_index(drop=True)\n",
    "x_raw = df.drop(['TIMESTAMP','Event'],axis=1).values\n",
    "y_raw = df['Event'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fbc4ff",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbe797",
   "metadata": {},
   "source": [
    "According to the results of isnull().sum(), the dataset contains no missing values. Therefore, all raw data are preserved without any additional processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723039a5",
   "metadata": {},
   "source": [
    "### Data split and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = LabelEncoder()\n",
    "y_encoded = encode.fit_transform(y_raw)\n",
    "print(f'Classes: {encode.classes_}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_raw, y_encoded, test_size=0.2, random_state=Seed, shuffle=True, stratify=y_encoded    \n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3d1c2",
   "metadata": {},
   "source": [
    "### Create sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X,y,sequence_length):\n",
    "    xs,ys = [],[]\n",
    "    for i in range(len(X)-sequence_length +1):\n",
    "        x_i = X[i:(i+sequence_length)]\n",
    "        y_i = y[i+sequence_length-1]\n",
    "        xs.append(x_i)\n",
    "        ys.append(y_i)\n",
    "    return np.array(xs),np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa879b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 10\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, sequence)\n",
    "X_test_seq,  y_test_seq  = create_sequences(X_test_scaled,  y_test,  sequence)\n",
    "\n",
    "print(X_train_seq.shape)\n",
    "print(y_train_seq.shape)\n",
    "print(X_test_seq.shape)\n",
    "print(y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41c8d8",
   "metadata": {},
   "source": [
    "### Batch loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMUDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "train_dataset = PMUDataset(X_train_seq, y_train_seq)\n",
    "test_dataset = PMUDataset(X_test_seq, y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Batch X shape:\", xb.shape)\n",
    "    print(\"Batch y shape:\", yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71047d",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1306a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNclassifier(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layer,num_classes):\n",
    "        super(RNNclassifier,self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layer,\n",
    "            batch_first=True,\n",
    "            nonlinearity='tanh'\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        out,hidden = self.rnn(x)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba29d4",
   "metadata": {},
   "source": [
    "### Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307aa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size =14\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "num_classes = len(encode.classes_)\n",
    "model = RNNclassifier(input_size,hidden_size,num_layers,num_classes).to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1d36f",
   "metadata": {},
   "source": [
    "### loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a08da8",
   "metadata": {},
   "source": [
    "### training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(device),yb.to(device)\n",
    "\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs,yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(test_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}  \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998f88c",
   "metadata": {},
   "source": [
    "# Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d491313",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds =[]\n",
    "all_true =[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb,yb in test_loader:\n",
    "        xb,yb = xb.to(device),yb.to(device)\n",
    "        outputs = model(xb)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_true.extend(yb.cpu().numpy())\n",
    "        \n",
    "print(\"Accuracy: \", accuracy_score(all_true, all_preds))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(all_true, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0759187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_true, all_preds)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f24187",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(train_losses, label=\"Training Loss\", linewidth=2)\n",
    "plt.plot(val_losses, label=\"Validation Loss\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36306e76",
   "metadata": {},
   "source": [
    "Replace the original loss with weighted cross-entropy to mitigate class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bdc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount(y_train)\n",
    "num_classes = len(class_counts)\n",
    "class_weights = (len(y_train))/(num_classes * class_counts)**0.5\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001,weight_decay=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
